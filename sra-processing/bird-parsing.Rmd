# SRA search and metadata setup code

This code reads in the results of manual SRA searches (in sra_searches.txt) and does cleanup and parsing to accomplish a few goals:
* identify candidate BioProjects for further examination to see if they are useable for this project
* produce metadata output for selected BioProjects to be parsed for read mapping and variant calling

Setup: load libraries, create functions

```{r}
library(tidyverse)
library(purrr)
library(stringr)

path_to_write = "."

read_sra_clean <- function(file, path) {
  df<-read_csv(paste0(path, "/", file), cols(.default="c"), col_names = TRUE) %>%
    select(Run, BioSample, Experiment, Instrument, LibrarySelection, LibrarySource, Organism, Platform, 
           SampleName = `Sample Name`, SRAStudy = `SRA Study`, Bases, AvgSpotLen, BioProject, sex, Isolate,
           Country = geo_loc_name_country, Continent = geo_loc_name_country_continent, Locality = geo_loc_name,
           Ecotype, Strain)
}

read_sra_full <- function(file, path) {
  df<-read_csv(paste0(path, "/", file), cols(.default="c"), col_names = TRUE)
}

read_assembly_clean <- function(file, path) {
  df<-read_tsv(paste0(path, "/", file, ".tsv"), col_names = TRUE) %>%
    rename_with(~ gsub(" ", "", .x, fixed=TRUE))
}
```

Now, load in all the SRA searches, combined, and parse. Use the read_sra_clean function just for ease of viewing. There may be some parsing errors (there are weird things in some column headers), but so far this has not seemed to matter. 
Note: to replicate, please unzip SraRunTable.txt.gz first.

```{r}

files<-c("SraRunTable.txt")

sra_list<-lapply(files, read_sra_clean, path=".")

#flatten to single tibble, with distinct in case of duplicates in searches

sra<-bind_rows(sra_list) %>% distinct()
```

Take a look at issues, first cleaning up metagenomic and suspcicious library selection methods, this may miss a few things but should be cleaner

```{r}

table(sra$LibrarySource)
table(sra$LibrarySelection)

sra_clean <- sra %>% filter(LibrarySource == "GENOMIC", 
              LibrarySelection == "RANDOM" | LibrarySelection == "unspecified" | LibrarySelection == "PCR" | LibrarySelection == "other" | LibrarySelection == "RANDOM PCR")
```

Next, get genome information, to filter out species that don't have a reference genome. Again, this will load manual searches. 

```{r}

assemblies <- read_assembly_clean("reference_bird_genomes", ".") %>% 
  mutate(Annotation = ifelse(is.na(AnnotationName), 0, 1)) %>% 
  select(Accession=AssemblyAccession, Organism=OrganismName, AssemblyName, AssemblyLevel, Annotation, AsmSize = AssemblyStatsTotalSequenceLength) %>%
  arrange(desc(Annotation)) %>%
  distinct(Organism, .keep_all = TRUE)
```


Next, make the preliminary list of possible popgen projects.

```{r}
popgen <- right_join(sra_clean, assemblies, by=c("Organism" = "Organism"), 
                     suffix = c(".popgen", ".assembly")) %>% 
  select(-Run, -Experiment, -Instrument) %>% group_by(BioSample) %>%
  mutate(bases_total = sum(as.numeric(Bases))) %>% 
  select(-Bases, -AvgSpotLen) %>%
  distinct() %>% 
  mutate(coverage = as.numeric(bases_total) / as.numeric(AsmSize))

#some quick analysis

popgen %>% mutate(covplot = ifelse(coverage < 100, coverage, 100)) %>% ggplot(aes(covplot)) + geom_histogram()
```


```{r}

#write out 

popgen %>% filter(coverage > 5) %>% group_by(Organism, BioProject, Annotation) %>% count() %>% filter(n > 10) %>%
  select(Organism, BioProject, Annotation) %>%
  write_tsv(file="bioprojects.tsv")
```

The output here, bioprojects.tsv, is manually curated to verify publication information and useability. This step is of course time consuming but hard to see how else to proceed as links between BioProjects and publications are spotty at best in databases.
